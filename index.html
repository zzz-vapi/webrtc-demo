<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Local WebRTC Chat</title>
    <style>
      body {
        background: #222;
        color: #f9f9f9;
        font-family: Arial, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
      }
      #log {
        border: 1px solid #444;
        padding: 10px;
        margin-top: 10px;
        height: 300px;
        overflow-y: auto;
        background: #333;
        color: #f9f9f9;
        display: flex;
        flex-direction: column;
      }
      .log-message {
        margin-bottom: 5px;
      }
      #inputContainer {
        margin-top: auto;
        display: flex;
        align-items: center;
      }
      #textInput {
        flex: 1;
        padding: 8px;
        margin-right: 4px;
        background: #444;
        color: #f9f9f9;
        border: 1px solid #555;
      }
      button {
        padding: 8px;
        background: #555;
        color: #f9f9f9;
        border: 1px solid #666;
        cursor: pointer;
      }
      .audio-container {
        margin: 10px 0;
        padding: 8px;
        background: #333;
        border: 1px solid #444;
        border-radius: 4px;
      }
      .volume-control {
        display: flex;
        align-items: center;
        gap: 8px;
      }
      #volumeSlider {
        width: 100px;
        accent-color: #555;
      }
      #muteButton {
        padding: 4px 8px;
        margin-right: 8px;
        background: #444;
        border: 1px solid #555;
        border-radius: 4px;
        cursor: pointer;
      }
      .status {
        margin: 10px 0;
        padding: 8px;
        border-radius: 4px;
        background: #444;
      }
      .status.connected {
        background: #2a5;
      }
      .status.disconnected {
        background: #a52;
      }
      .button-group {
        display: flex;
        gap: 10px;
        margin: 10px 0;
      }
      #startButton {
        background: #2a5;
      }
      #endButton {
        background: #a52;
        display: none;
      }
      #startSpeakButton {
        background: #2a5;
      }
      #endSpeakButton {
        background: #a52;
        display: none;
      }
      #settingsButton {
        background: #555;
      }
      .input-control {
        margin-top: 10px;
      }
      #audioInput {
        padding: 8px;
        background: #444;
        color: #f9f9f9;
        border: 1px solid #555;
      }
    </style>
  </head>
  <body>
    <h1>Local WebRTC Chat</h1>
    <p>Click below to start/end a session with the local WebRTC server.</p>

    <div id="status" class="status disconnected">Disconnected</div>
    <div class="button-group">
      <button id="startButton">ðŸŸ¢ Start Session</button>
      <button id="startSpeakButton">ðŸŽ¤ Start Speak</button>
    </div>

    <div class="audio-container">
      <audio id="remoteAudio" autoplay></audio>
      <div class="volume-control">
        <label for="volumeSlider">Remote Audio Control: </label>
        <button id="muteButton">ðŸ”Š</button>
        <input
          type="range"
          id="volumeSlider"
          min="0"
          max="1"
          step="0.1"
          value="1"
        />
      </div>
      <div class="input-control">
        <label for="audioInput">Microphone: </label>
        <select id="audioInput"></select>
      </div>
    </div>

    <div id="log">
      <div id="inputContainer">
        <input
          id="textInput"
          type="text"
          placeholder="Type your message here"
        />
        <button id="sendButton">Send</button>
      </div>
    </div>

    <script>
      // WebRTC globals
      let pc; // RTCPeerConnection
      let track; // Local audio track
      let dc; // Data channel
      let ws; // WebSocket for signaling
      let localStream; // Local media stream
      let isCallActive = false; // Call state
      let isSpeaking = false; // Speaking state
      let speakDebounceTimer = null; // Debounce timer for speak button

      // DOM elements
      const remoteAudioEl = document.getElementById("remoteAudio");
      const muteButton = document.getElementById("muteButton");
      const volumeSlider = document.getElementById("volumeSlider");
      const logEl = document.getElementById("log");
      const inputContainerEl = document.getElementById("inputContainer");
      const textInputEl = document.getElementById("textInput");
      const sendButtonEl = document.getElementById("sendButton");
      const statusEl = document.getElementById("status");
      const startButtonEl = document.getElementById("startButton");
      const endButtonEl = document.getElementById("endButton");
      const startSpeakButtonEl = document.getElementById("startSpeakButton");
      const endSpeakButtonEl = document.getElementById("endSpeakButton");
      const settingsButtonEl = document.getElementById("settingsButton");
      const audioInputEl = document.getElementById("audioInput");

      // WebSocket connection
      function connectWebSocket() {
        const wsUrl = `ws://${window.location.host}/ws`;
        console.log("Connecting to WebSocket:", wsUrl);
        ws = new WebSocket(wsUrl);

        ws.onopen = () => {
          console.log("WebSocket connection established");
          appendLog("Connected to server");
          startButtonEl.disabled = false;
          updateStatus(true);
        };

        ws.onclose = (event) => {
          console.log("WebSocket disconnected:", event.code, event.reason);
          appendLog("WebSocket disconnected");
          startButtonEl.disabled = true;
          updateStatus(false);

          // Attempt to reconnect after 3 seconds
          setTimeout(() => {
            console.log("Attempting to reconnect...");
            connectWebSocket();
          }, 3000);
        };

        ws.onerror = (error) => {
          console.error("WebSocket error:", error);
          appendLog("WebSocket error occurred");
        };

        ws.onmessage = async (event) => {
          try {
            const message = JSON.parse(event.data);
            console.log("Received message:", message);
            switch (message.type) {
              case "offer":
                await handleOffer(message);
                break;
              case "answer":
                await handleAnswer(message);
                break;
              case "ice-candidate":
                await handleIceCandidate(message);
                break;
            }
          } catch (err) {
            console.error("Error handling message:", err);
            appendLog("Error handling message: " + err.message);
          }
        };
      }

      // Handle incoming offer
      async function handleOffer(message) {
        if (pc) {
          await pc.setRemoteDescription(new RTCSessionDescription(message));
          const answer = await pc.createAnswer();
          await pc.setLocalDescription(answer);
          ws.send(
            JSON.stringify({
              type: "answer",
              sdp: pc.localDescription,
            })
          );
        }
      }

      // Handle incoming answer
      async function handleAnswer(message) {
        if (pc) {
          await pc.setRemoteDescription(new RTCSessionDescription(message));
        }
      }

      // Handle incoming ICE candidate
      async function handleIceCandidate(message) {
        if (pc) {
          await pc.addIceCandidate(new RTCIceCandidate(message.candidate));
        }
      }

      // Get available audio input devices
      async function getAudioInputs() {
        try {
          const devices = await navigator.mediaDevices.enumerateDevices();
          const audioInputs = devices.filter(
            (device) => device.kind === "audioinput"
          );

          console.log(
            "Available audio input devices:",
            audioInputs.map((d) => ({
              id: d.deviceId,
              label: d.label,
              kind: d.kind,
            }))
          );

          // Clear existing options
          audioInputEl.innerHTML = "";

          // Add options for each audio input
          audioInputs.forEach((device) => {
            const option = document.createElement("option");
            option.value = device.deviceId;
            option.text =
              device.label || `Microphone ${audioInputEl.length + 1}`;
            audioInputEl.appendChild(option);
            console.log("Added audio input option:", {
              id: device.deviceId,
              label: device.label,
              kind: device.kind,
            });
          });

          // If no devices are available yet, request permissions
          if (audioInputs.length === 0) {
            console.log("No audio devices found, requesting permissions...");
            await navigator.mediaDevices.getUserMedia({ audio: true });
            // Refresh the list after getting permissions
            getAudioInputs();
          }
        } catch (err) {
          console.error("Error getting audio inputs:", err);
          appendLog("Error getting audio inputs: " + err.message);
        }
      }

      // Start WebRTC session
      async function startSession() {
        try {
          // Create peer connection
          pc = new RTCPeerConnection({
            iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
          });

          // Handle remote track
          pc.ontrack = (e) => {
            console.log("Received remote track:", e.track.kind, e.track.id);
            remoteAudioEl.srcObject = e.streams[0];
            appendLog("Remote audio track received");
          };

          // Create data channel
          dc = pc.createDataChannel("chat");
          setupDataChannel();

          // Get local audio stream with selected device
          const selectedDeviceId = audioInputEl.value;
          console.log("Selected audio device ID:", selectedDeviceId);

          const constraints = {
            audio: {
              deviceId: selectedDeviceId
                ? { exact: selectedDeviceId }
                : undefined,
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true,
            },
          };
          console.log("Audio constraints:", constraints);

          localStream = await navigator.mediaDevices.getUserMedia(constraints);
          [track] = localStream.getAudioTracks();
          console.log("Local audio track created:", {
            kind: track.kind,
            id: track.id,
            enabled: track.enabled,
            muted: track.muted,
            label: track.label,
            deviceId: track.getSettings().deviceId,
          });

          // Add local track before creating offer
          const sender = pc.addTrack(track, localStream);
          console.log(
            "Added track sender:",
            sender.track?.kind,
            sender.track?.id
          );

          // Create and send offer with explicit audio capabilities
          const offer = await pc.createOffer({
            offerToReceiveAudio: true,
            offerToReceiveVideo: false,
          });
          console.log("Created offer with audio capabilities");

          await pc.setLocalDescription(offer);
          ws.send(
            JSON.stringify({
              type: "offer",
              sdp: pc.localDescription,
            })
          );

          // Handle ICE candidates
          pc.onicecandidate = (event) => {
            if (event.candidate) {
              ws.send(
                JSON.stringify({
                  type: "ice-candidate",
                  candidate: event.candidate,
                })
              );
            }
          };

          // Handle connection state changes
          pc.onconnectionstatechange = () => {
            appendLog(`Connection state: ${pc.connectionState}`);
            if (pc.connectionState === "connected") {
              updateStatus(true);
              startSpeakButtonEl.disabled = false;
              toggleSessionButtons(true); // Show End Session button when connected
            } else if (
              pc.connectionState === "disconnected" ||
              pc.connectionState === "failed"
            ) {
              updateStatus(false);
              startSpeakButtonEl.disabled = true;
              toggleSessionButtons(false); // Show Start Session button when disconnected
            }
          };

          // Handle ICE connection state changes
          pc.oniceconnectionstatechange = () => {
            appendLog(`ICE connection state: ${pc.iceConnectionState}`);
          };

          // Handle ICE gathering state changes
          pc.onicegatheringstatechange = () => {
            appendLog(`ICE gathering state: ${pc.iceGatheringState}`);
          };

          appendLog("Session started");
        } catch (err) {
          console.error("Error starting session:", err);
          appendLog("Error starting session: " + err.message);
          updateStatus(false);
          toggleSessionButtons(false);
        }
      }

      // Setup data channel
      function setupDataChannel() {
        dc.onopen = () => {
          appendLog("Data channel opened");
        };

        dc.onmessage = (event) => {
          appendLog("Server: " + event.data);
        };

        dc.onclose = () => {
          appendLog("Data channel closed");
        };
      }

      // UI helpers
      function toggleSessionButtons(isSessionActive) {
        // Toggle between Start/End Session button
        if (isSessionActive) {
          startButtonEl.textContent = "ðŸ”´ End Session";
          startButtonEl.disabled = false;
        } else {
          startButtonEl.textContent = "ðŸŸ¢ Start Session";
          startButtonEl.disabled = false;
        }
      }

      function toggleSpeakButtons(isSpeaking) {
        // Toggle between Start/End Speak button
        if (isSpeaking) {
          startSpeakButtonEl.textContent = "â¹ï¸ End Speak";
          startSpeakButtonEl.disabled = false; // Ensure button is enabled when speaking
        } else {
          startSpeakButtonEl.textContent = "ðŸŽ¤ Start Speak";
          startSpeakButtonEl.disabled = false; // Ensure button is enabled when not speaking
        }
      }

      function updateStatus(connected) {
        statusEl.textContent = connected ? "Connected" : "Disconnected";
        statusEl.className = `status ${
          connected ? "connected" : "disconnected"
        }`;
        // Only disable the speak button if we're not connected
        if (!connected) {
          startSpeakButtonEl.disabled = true;
        }
      }

      // Append message to log
      function appendLog(message) {
        const logEntry = document.createElement("div");
        logEntry.textContent = message;
        logEntry.classList.add("log-message");
        logEl.insertBefore(logEntry, inputContainerEl);
        logEl.scrollTop = logEl.scrollHeight;
      }

      // Start speak
      async function startSpeak() {
        try {
          // Prevent duplicate events
          if (isSpeaking) {
            console.log("Already speaking, ignoring start speak");
            return;
          }

          // Send start speak message
          if (dc && dc.readyState === "open") {
            dc.send(JSON.stringify({ type: "start_speak" }));
            console.log("Sent start_speak message");
          }

          isSpeaking = true;
          isCallActive = true;
          toggleSpeakButtons(true);
          appendLog("Started speaking");
        } catch (err) {
          console.error("Error starting speak:", err);
          appendLog("Error starting speak: " + err.message);
          isSpeaking = false;
          isCallActive = false;
          toggleSpeakButtons(false);
        }
      }

      // End speak
      async function endSpeak() {
        try {
          // Prevent duplicate events
          if (!isSpeaking) {
            console.log("Not speaking, ignoring end speak");
            return;
          }

          // Send end speak message immediately
          if (dc && dc.readyState === "open") {
            dc.send(JSON.stringify({ type: "end_speak" }));
            console.log("Sent end_speak message");
          }

          isSpeaking = false;
          isCallActive = false;
          toggleSpeakButtons(false);
          appendLog("Ended speaking");
        } catch (err) {
          console.error("Error ending speak:", err);
          appendLog("Error ending speak: " + err.message);
          isSpeaking = false;
          isCallActive = false;
          toggleSpeakButtons(false);
        }
      }

      // End session
      async function endSession() {
        if (isSpeaking) {
          await endSpeak();
        }
        if (dc) {
          dc.close();
        }
        if (pc) {
          pc.close();
        }
        isSpeaking = false;
        isCallActive = false;
        toggleSessionButtons(false);
        updateStatus(false);
        appendLog("Session ended");
      }

      // Send message through data channel
      function sendMessage() {
        const text = textInputEl.value.trim();
        if (text && dc && dc.readyState === "open") {
          dc.send(text);
          appendLog("You: " + text);
          textInputEl.value = "";
        }
      }

      // Event listeners
      startButtonEl.addEventListener("click", async () => {
        if (pc?.connectionState === "connected") {
          // End session
          if (isSpeaking) {
            await endSpeak();
          }
          await endSession();
        } else {
          // Start session
          await startSession();
        }
      });

      // Single event listener for speak button
      startSpeakButtonEl.addEventListener("click", () => {
        if (isSpeaking) {
          endSpeak();
        } else {
          startSpeak();
        }
      });

      sendButtonEl.addEventListener("click", sendMessage);
      textInputEl.addEventListener("keydown", (ev) => {
        if (ev.key === "Enter") {
          sendMessage();
        }
      });

      volumeSlider.addEventListener(
        "input",
        (e) => (remoteAudioEl.volume = e.target.value)
      );
      muteButton.addEventListener("click", () => {
        const isMuted = remoteAudioEl.muted;
        remoteAudioEl.muted = !isMuted;
        muteButton.textContent = isMuted ? "ðŸ”Š" : "ðŸ”‡";
      });

      audioInputEl.addEventListener("change", async () => {
        if (pc?.connectionState === "connected") {
          // If we're already connected, we need to restart the session
          appendLog("Changing audio input requires session restart");
          await endSession();
          await startSession();
        }
      });

      // Initialize WebSocket connection and get audio inputs
      connectWebSocket();
      getAudioInputs();
    </script>
  </body>
</html>
